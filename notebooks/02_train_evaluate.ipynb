{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA \u2192 Model Selection: Ready-to-Run Evaluation\n",
        "This notebook demonstrates the corrected, leakage-safe workflow:\n",
        "1. Load data (no internet needed)\n",
        "2. Split (stratified if classification)\n",
        "3. Build leakage-safe Pipelines (missingness flags + ColumnTransformer)\n",
        "4. Train baseline (penalized linear/logistic)\n",
        "5. Optional GBM (LightGBM/XGBoost if installed)\n",
        "6. Diagnostics: ROC/PR & calibration (classification) or residuals (regression)\n",
        "7. Final test evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "TASK = 'classification'  # 'classification' or 'regression'\n",
        "RANDOM_STATE = 42\n",
        "N_SPLITS = 5\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "from src.data.loaders import load_classification_breast_cancer, load_regression_synthetic, split_data\n",
        "from src.features.pipelines import build_leakage_safe_preprocessor\n",
        "from src.models.baselines import ridge_regressor, elasticnet_regressor, robust_huber_regressor, penalized_logistic, log1p_wrapper\n",
        "from src.models.gbm import xgb_regressor, xgb_classifier, lgbm_regressor, lgbm_classifier\n",
        "from src.evaluation.metrics import classification_metrics, regression_metrics\n",
        "from src.evaluation.plots import plot_roc_pr, plot_calibration, plot_residuals\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (6,4)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 1) Load dataset and split\n",
        "if TASK == 'classification':\n",
        "    X, y = load_classification_breast_cancer()\n",
        "else:\n",
        "    X, y = load_regression_synthetic()\n",
        "\n",
        "data = split_data(X, y, task=TASK, random_state=RANDOM_STATE)\n",
        "data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 2) Build leakage-safe preprocessor\n",
        "pre = build_leakage_safe_preprocessor(data.X_train)\n",
        "pre\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 3) Baseline model\n",
        "if TASK == 'classification':\n",
        "    base = penalized_logistic(random_state=RANDOM_STATE)\n",
        "else:\n",
        "    base = ridge_regressor(random_state=RANDOM_STATE)\n",
        "base_pipe = Pipeline([('prep', pre), ('model', base)])\n",
        "base_pipe.fit(data.X_train, data.y_train)\n",
        "\n",
        "if TASK == 'classification':\n",
        "    y_proba = base_pipe.predict_proba(data.X_valid)[:,1]\n",
        "    base_scores = classification_metrics(data.y_valid, y_proba)\n",
        "    base_scores\n",
        "else:\n",
        "    y_pred = base_pipe.predict(data.X_valid)\n",
        "    base_scores = regression_metrics(data.y_valid, y_pred)\n",
        "    base_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 4) Optional GBM (LightGBM preferred; fallback to XGBoost). Skips automatically if not installed.\n",
        "best_pipe = base_pipe\n",
        "if TASK == 'classification':\n",
        "    gbm = lgbm_classifier(random_state=RANDOM_STATE) or xgb_classifier(random_state=RANDOM_STATE)\n",
        "    if gbm is not None:\n",
        "        gbm_pipe = Pipeline([('prep', pre), ('model', gbm)])\n",
        "        gbm_pipe.fit(data.X_train, data.y_train)\n",
        "        y_gbm = gbm_pipe.predict_proba(data.X_valid)[:,1]\n",
        "        gbm_scores = classification_metrics(data.y_valid, y_gbm)\n",
        "        display({'baseline': base_scores, 'gbm': gbm_scores})\n",
        "        if gbm_scores['roc_auc'] > base_scores['roc_auc']:\n",
        "            best_pipe = gbm_pipe\n",
        "else:\n",
        "    gbm = lgbm_regressor(random_state=RANDOM_STATE) or xgb_regressor(random_state=RANDOM_STATE)\n",
        "    if gbm is not None:\n",
        "        gbm_pipe = Pipeline([('prep', pre), ('model', gbm)])\n",
        "        gbm_pipe.fit(data.X_train, data.y_train)\n",
        "        y_gbm = gbm_pipe.predict(data.X_valid)\n",
        "        from src.evaluation.metrics import regression_metrics\n",
        "        gbm_scores = regression_metrics(data.y_valid, y_gbm)\n",
        "        display({'baseline': base_scores, 'gbm': gbm_scores})\n",
        "        if gbm_scores['rmse'] < base_scores['rmse']:\n",
        "            best_pipe = gbm_pipe\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 5) Diagnostics\n",
        "if TASK == 'classification':\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    y_proba_valid = best_pipe.predict_proba(data.X_valid)[:,1]\n",
        "    plot_roc_pr(data.y_valid, y_proba_valid)\n",
        "    plot_calibration(data.y_valid, y_proba_valid)\n",
        "else:\n",
        "    y_pred_valid = best_pipe.predict(data.X_valid)\n",
        "    plot_residuals(data.y_valid, y_pred_valid)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 6) Final fit, optional calibration (classification), and test evaluation\n",
        "from sklearn.metrics import roc_auc_score\n",
        "if TASK == 'classification':\n",
        "    try:\n",
        "        calib = CalibratedClassifierCV(best_pipe, method='isotonic', cv=5)\n",
        "        calib.fit(pd.concat([data.X_train, data.X_valid]), pd.concat([data.y_train, data.y_valid]))\n",
        "        y_proba_test = calib.predict_proba(data.X_test)[:,1]\n",
        "        print('Test ROC-AUC (calibrated):', roc_auc_score(data.y_test, y_proba_test))\n",
        "        plot_calibration(data.y_test, y_proba_test)\n",
        "    except Exception as e:\n",
        "        warnings.warn(f'Calibration failed: {e}')\n",
        "        best_pipe.fit(pd.concat([data.X_train, data.X_valid]), pd.concat([data.y_train, data.y_valid]))\n",
        "        y_proba_test = best_pipe.predict_proba(data.X_test)[:,1]\n",
        "        print('Test ROC-AUC (uncalibrated):', roc_auc_score(data.y_test, y_proba_test))\n",
        "else:\n",
        "    best_pipe.fit(pd.concat([data.X_train, data.X_valid]), pd.concat([data.y_train, data.y_valid]))\n",
        "    y_pred_test = best_pipe.predict(data.X_test)\n",
        "    from src.evaluation.metrics import regression_metrics\n",
        "    print('Test scores:', regression_metrics(data.y_test, y_pred_test))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}