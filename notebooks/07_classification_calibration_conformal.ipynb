{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Temperature Scaling and Selective Conformal Classification (Binary)\n",
        "We train a classifier, show calibration, apply **temperature scaling**, and then build a **selective classifier** with a conformal-style risk control (abstention) that guarantees validation error \u2264 \u03b1 among auto-decisions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
        "from sklearn.calibration import calibration_curve\n",
        "from src.data.loaders import load_classification_breast_cancer\n",
        "from src.features.pipelines import build_leakage_safe_preprocessor\n",
        "from src.models.gbm import lgbm_classifier\n",
        "from src.calibration.temperature import TemperatureScaler\n",
        "from src.calibration.conformal import selective_threshold, selective_predict\n",
        "\n",
        "plt.rcParams['figure.figsize']=(6,4)\n",
        "ALPHA = 0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "X, y = load_classification_breast_cancer()\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "X_tr, X_va, y_tr, y_va = train_test_split(X_tr, y_tr, test_size=0.3, stratify=y_tr, random_state=42)\n",
        "pre = build_leakage_safe_preprocessor(X_tr)\n",
        "gbm = lgbm_classifier()\n",
        "pipe = Pipeline([('prep', pre), ('model', gbm)])\n",
        "pipe.fit(X_tr, y_tr)\n",
        "p_va = pipe.predict_proba(X_va)[:,1]\n",
        "p_te = pipe.predict_proba(X_te)[:,1]\n",
        "print('Valid AUC:', roc_auc_score(y_va, p_va), '| Brier:', brier_score_loss(y_va, p_va))\n",
        "print('Test  AUC:', roc_auc_score(y_te, p_te), '| Brier:', brier_score_loss(y_te, p_te))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Reliability before temperature scaling\n",
        "prob_true, prob_pred = calibration_curve(y_va, p_va, n_bins=10, strategy='quantile')\n",
        "plt.plot(prob_pred, prob_true, marker='o'); plt.plot([0,1],[0,1],'--')\n",
        "plt.title('Calibration (valid) before temp scaling'); plt.xlabel('Predicted'); plt.ylabel('Fraction positive'); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Temperature scaling on validation\n",
        "ts = TemperatureScaler().fit(y_va, p_va)\n",
        "p_va_cal = ts.transform(p_va)\n",
        "p_te_cal = ts.transform(p_te)\n",
        "print('Temp T:', ts.T_)\n",
        "print('Valid (cal): Brier', brier_score_loss(y_va, p_va_cal))\n",
        "print(' Test (cal): Brier', brier_score_loss(y_te, p_te_cal))\n",
        "prob_true, prob_pred = calibration_curve(y_va, p_va_cal, n_bins=10, strategy='quantile')\n",
        "plt.plot(prob_pred, prob_true, marker='o'); plt.plot([0,1],[0,1],'--')\n",
        "plt.title('Calibration (valid) after temp scaling'); plt.xlabel('Predicted'); plt.ylabel('Fraction positive'); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Selective conformal threshold on validation (risk control)\n",
        "tau, summary = selective_threshold(y_va, p_va_cal, alpha=ALPHA)\n",
        "print('Selective threshold tau:', tau, '| summary:', summary)\n",
        "pred_te, abstain = selective_predict(p_te_cal, tau)\n",
        "auto_mask = (pred_te != -1)\n",
        "err_rate = np.mean(pred_te[auto_mask] != y_te[auto_mask]) if auto_mask.any() else 0.0\n",
        "coverage = np.mean(auto_mask)\n",
        "print(f'Auto-decision coverage on test: {coverage:.3f}; empirical error among auto decisions: {err_rate:.3f} (target <= {ALPHA})')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}